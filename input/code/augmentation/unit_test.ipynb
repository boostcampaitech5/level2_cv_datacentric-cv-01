{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageDraw\n",
    "import os.path as osp\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "from shapely.geometry import Polygon\n",
    "from functools import partial\n",
    "from augmentation import generate_roi_mask\n",
    "from matplotlib import pyplot as plt\n",
    "from augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_to_tuple(v):\n",
    "    new_v = list(map(tuple,v))\n",
    "    return new_v\n",
    "def xy_to_xandy(v):\n",
    "    x,y=list(map(list,zip(*v)))\n",
    "    return x,y\n",
    "def find_min_box_from_polygon(vertices):\n",
    "    rot_v=np.array(vertices)\n",
    "    vertices.append(vertices[0])\n",
    "    x,y=xy_to_xandy(rot_v)\n",
    "    angle = []\n",
    "    for i in range(len(y)-1):\n",
    "        y[i]=-(y[i]-y[i+1])\n",
    "        x[i]=-(x[i]-x[i+1])\n",
    "    x.pop()\n",
    "    y.pop()\n",
    "    angle= -np.arctan2(np.array(y),np.array(x))\n",
    "    min_area = None\n",
    "    target_angle = None\n",
    "    for ang in angle:\n",
    "        rotate_mat = np.array([[np.cos(ang),-np.sin(ang)],\n",
    "                            [np.sin(ang),np.cos(ang)]])\n",
    "        new_v = rotate_mat@rot_v.T\n",
    "        poly_area = (np.max(new_v[0])-np.min(new_v[0])) * (np.max(new_v[1])-np.min(new_v[1]) )\n",
    "        if min_area==None or poly_area<min_area:\n",
    "            min_area=poly_area\n",
    "            min_bbox = np.array([[np.min(new_v[0]),np.min(new_v[1])],\n",
    "                            [np.max(new_v[0]),np.min(new_v[1])],\n",
    "                            [np.max(new_v[0]),np.max(new_v[1])],\n",
    "                            [np.min(new_v[0]),np.max(new_v[1])]])\n",
    "            target_angle = ang\n",
    "    new_bbox = min_bbox\n",
    "    reverse_mat = np.array([[np.cos(target_angle),np.sin(target_angle)],\n",
    "                        [-np.sin(target_angle),np.cos(target_angle)]])\n",
    "    new_polygon = (reverse_mat)@new_bbox.T\n",
    "    new_polygon = list(map(tuple,zip(*new_polygon.tolist())))\n",
    "    return new_polygon\n",
    "\n",
    "def filter_vertices(vertices, labels, ignore_under=0, drop_under=0):\n",
    "    if drop_under == 0 and ignore_under == 0:\n",
    "        return vertices, labels\n",
    "\n",
    "    new_vertices, new_labels = vertices.copy(), labels.copy()\n",
    "\n",
    "    areas = np.array([Polygon(v.reshape((4, 2))).convex_hull.area for v in vertices])\n",
    "    labels[areas < ignore_under] = 0\n",
    "\n",
    "    if drop_under > 0:\n",
    "        passed = areas >= drop_under\n",
    "        new_vertices, new_labels = new_vertices[passed], new_labels[passed]\n",
    "\n",
    "    return new_vertices, new_labels\n",
    "\n",
    "class SceneTextDataset(Dataset):\n",
    "    def __init__(self, root_dir,\n",
    "                 split='train',\n",
    "                 image_size=2048,\n",
    "                 crop_size=1024,\n",
    "                 ignore_tags=[],\n",
    "                 ignore_under_threshold=10,\n",
    "                 drop_under_threshold=1,\n",
    "                 polygon_masking=False,\n",
    "                 aug_list=[]):\n",
    "        with open(osp.join(root_dir, 'ufo/{}.json'.format(split)), 'r') as f:\n",
    "            anno = json.load(f)\n",
    "\n",
    "        self.anno = anno\n",
    "        self.image_fnames = sorted(anno['images'].keys())\n",
    "        self.image_dir = osp.join(root_dir, 'img', split)\n",
    "\n",
    "        self.image_size, self.crop_size = image_size, crop_size\n",
    "\n",
    "        self.ignore_tags = ignore_tags\n",
    "\n",
    "        self.drop_under_threshold = drop_under_threshold\n",
    "        self.ignore_under_threshold = ignore_under_threshold\n",
    "\n",
    "        self.aug_list = aug_list\n",
    "        self.polygon_masking = polygon_masking\n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_fname = self.image_fnames[idx]\n",
    "        image_fpath = osp.join(self.image_dir, image_fname)\n",
    "\n",
    "        vertices, labels = [], []\n",
    "        masking_vertices = []\n",
    "        for word_info in self.anno['images'][image_fname]['words'].values():\n",
    "            word_tags = word_info['tags']\n",
    "\n",
    "            ignore_sample = any(elem for elem in word_tags if elem in self.ignore_tags)\n",
    "            num_pts = np.array(word_info['points']).shape[0]\n",
    "\n",
    "            # skip samples with ignore tag and\n",
    "            # samples with number of points greater than 4\n",
    "            if ignore_sample :\n",
    "                continue\n",
    "            if num_pts > 4:\n",
    "                if self.polygon_masking:\n",
    "                    masking_vertices.append(list(map(tuple,word_info['points'])))\n",
    "                elif True:\n",
    "                    vertices.append(find_min_box_from_polygon(word_info['points']))\n",
    "                    labels.append(int(not word_info['illegibility']))\n",
    "                continue\n",
    "            vertices.append(np.array(word_info['points']).flatten())\n",
    "            labels.append(int(not word_info['illegibility']))\n",
    "        vertices, labels = np.array(vertices, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "        vertices, labels = filter_vertices(\n",
    "            vertices,\n",
    "            labels,\n",
    "            ignore_under=self.ignore_under_threshold,\n",
    "            drop_under=self.drop_under_threshold\n",
    "        )\n",
    "\n",
    "        image = Image.open(image_fpath)\n",
    "        if masking_vertices and self.polygon_masking:\n",
    "            AnotationMasking(image,masking_vertices)\n",
    "        if self.aug_list:\n",
    "            image,vertices,labels=process_augmentation(image,vertices,labels,self.aug_list)\n",
    "        else:\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            image = np.array(image)\n",
    "    \n",
    "        word_bboxes = np.reshape(vertices, (-1, 4, 2))\n",
    "        roi_mask = generate_roi_mask(image, vertices, labels)\n",
    "\n",
    "        return image, word_bboxes, roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xy_to_xandy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m dataset \u001b[39m=\u001b[39m SceneTextDataset(\n\u001b[1;32m     10\u001b[0m data_dir,\n\u001b[1;32m     11\u001b[0m split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m polygon_masking\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m idx\u001b[39m=\u001b[39m\u001b[39m93\u001b[39m\n\u001b[0;32m---> 20\u001b[0m img\u001b[39m=\u001b[39mdataset[idx]\n\u001b[1;32m     22\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m25\u001b[39m,\u001b[39m40\u001b[39m))\n\u001b[1;32m     23\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m, in \u001b[0;36mSceneTextDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m     masking_vertices\u001b[39m.\u001b[39mappend(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mtuple\u001b[39m,word_info[\u001b[39m'\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m'\u001b[39m])))\n\u001b[1;32m     96\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     vertices\u001b[39m.\u001b[39mappend(find_min_box_from_polygon(word_info[\u001b[39m'\u001b[39;49m\u001b[39mpoints\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m     98\u001b[0m     labels\u001b[39m.\u001b[39mappend(\u001b[39mint\u001b[39m(\u001b[39mnot\u001b[39;00m word_info[\u001b[39m'\u001b[39m\u001b[39millegibility\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m     99\u001b[0m \u001b[39mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mfind_min_box_from_polygon\u001b[0;34m(vertices)\u001b[0m\n\u001b[1;32m      2\u001b[0m rot_v\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(vertices)\n\u001b[1;32m      3\u001b[0m vertices\u001b[39m.\u001b[39mappend(vertices[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m x,y\u001b[39m=\u001b[39mxy_to_xandy(rot_v)\n\u001b[1;32m      5\u001b[0m angle \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xy_to_xandy' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = os.environ.get('SM_CHANNEL_TRAIN', '../../data/medical')\n",
    "image_size = 2048\n",
    "input_size = 1024\n",
    "ignore_tags = ['masked', 'excluded-region', 'maintable', 'stamp']\n",
    "\n",
    "test_aug = []\n",
    "# test_aug = ['Resize','Rotate','ToNumpy','ColorJitter']\n",
    "\n",
    "dataset = SceneTextDataset(\n",
    "data_dir,\n",
    "split='train',\n",
    "image_size=image_size,\n",
    "crop_size=input_size,\n",
    "ignore_tags=ignore_tags,\n",
    "aug_list=test_aug,\n",
    "polygon_masking=False\n",
    ")\n",
    "\n",
    "idx=93\n",
    "img=dataset[idx]\n",
    "\n",
    "plt.figure(figsize=(25,40))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[0])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "dataset.aug_list=['Resize','AdjustHeight','Rotate','ToNumpy','RandomShadow']\n",
    "img=dataset[idx]\n",
    "print(img[0].max(),img[0].min())\n",
    "plt.imshow(img[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
